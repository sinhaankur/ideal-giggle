Warning: AI models not available. Using mock responses.

    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  AI Companion - On-Device AI (Edge AI)                â•‘
    â•‘                                                       â•‘
    â•‘  ğŸŒ Server running on:                                â•‘
    â•‘     http://localhost:5000                              â•‘
    â•‘                                                       â•‘
    â•‘  ğŸ¤– On-Device AI Features:                            â•‘
    â•‘     - Local Ollama Integration (Port 11434)          â•‘
    â•‘     - Privacy-First - All data stays local           â•‘
    â•‘     - No cloud API calls needed                      â•‘
    â•‘     - Real-time chat & emotion detection            â•‘
    â•‘                                                       â•‘
    â•‘  ğŸ“Š API Endpoints:                                    â•‘
    â•‘     - POST /api/companion/chat     - Chat with AI    â•‘
    â•‘     - POST /api/companion/create   - Create companionâ•‘
    â•‘     - GET  /api/ai/health          - AI health check â•‘
    â•‘     - GET  /api/ai/models          - Available modelsâ•‘
    â•‘                                                       â•‘
    â•‘  ğŸ™ï¸  Features:                                        â•‘
    â•‘     âœ“ Continuous voice input                         â•‘
    â•‘     âœ“ Emotion detection (ML5.js)                     â•‘
    â•‘     âœ“ Calendar sync support                          â•‘
    â•‘     âœ“ Multi-companion support                        â•‘
    â•‘                                                       â•‘
    â•‘  ğŸ’¡ Make sure Ollama is running on port 11434        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
 * Serving Flask app 'app'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.88.111.101:5000
[33mPress CTRL+C to quit[0m
127.0.0.1 - - [12/Feb/2026 02:39:28] "GET /api/ai/status HTTP/1.1" 200 -
127.0.0.1 - - [12/Feb/2026 02:39:55] "[31m[1mGET /api/companion/chat HTTP/1.1[0m" 405 -
127.0.0.1 - - [12/Feb/2026 02:40:04] "GET / HTTP/1.1" 200 -
